import os
import re
from pathlib import Path

def get_config(file, var):
    if not os.path.exists(file): return "N/A"
    content = Path(file).read_text()
    match = re.search(f"{var} = [\"']?(.*?)[\"']?$", content, re.M)
    return match.group(1) if match else "Not Set"

# Audit Current Configs
embed_model = get_config('build_kb.py', 'EMBED_MODEL')
chunk_size = get_config('build_kb.py', 'CHUNK_SIZE')
sim_threshold = get_config('vault_query.py', 'SIM_THRESHOLD')

doc_content = f"""
# üöÄ LLM Vault: System Overview
*Auto-generated Status Report*

## üõ† Project Configuration
- **Module 4 (LLM):** Using `{get_config('vault_query.py', 'CHAT_MODEL')}`
- **Module 3 (Vector DB):** `{embed_model}` with `{chunk_size}` char chunks
- **Retrieval Logic:** Cosine Similarity (Threshold: `{sim_threshold}`)

## üìö Study Mapping (From Handwritten Notes)
| Module | Topic | Status | Note Reference |
| :--- | :--- | :--- | :--- |
| **Module 1** | RAG Architecture | ‚úÖ Active | Retrieval + Generation split |
| **Module 2** | Keyword Search | ‚ö†Ô∏è Lacking | Needs BM25/TF-IDF "Plateau" logic |
| **Module 3** | Vector Retrieval | ‚úÖ Active | Cosine Similarity & KNN loop |
| **Module 4** | LLM Generation | ‚úÖ Active | Autoregressive token generation |

## üìÇ Vault Stats
- **Total Chunks in `kb.json`:** (Processed from your resumes folder)
"""
Path("SYSTEM_OVERVIEW.md").write_text(doc_content)